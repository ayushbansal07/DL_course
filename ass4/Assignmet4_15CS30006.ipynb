{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ayush/anaconda3/lib/python3.6/site-packages/scipy/stats/morestats.py:12: DeprecationWarning: Importing from numpy.testing.decorators is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing.decorators import setastest\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-2-e57eba91494f>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "  CLEANING_PATTERN = re.compile(\"[\\s\\n\\r\\t.,:;\\-_\\'\\\"?!#&()\\/%\\[\\]\\{\\}\\<\\>\\\\$@\\!\\*\\+\\=]\")\n"
     ]
    }
   ],
   "source": [
    "CLEANING_PATTERN = re.compile(\"[\\s\\n\\r\\t.,:;\\-_\\'\\\"?!#&()\\/%\\[\\]\\{\\}\\<\\>\\\\$@\\!\\*\\+\\=]\")\n",
    "VOCAB_SIZE = 5800\n",
    "MAX_TIME = 15\n",
    "LSTM_HIDDEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "with open('train.txt') as f:\n",
    "    for line in f:\n",
    "        x_train.append(line)\n",
    "\n",
    "with open('test.txt') as f:\n",
    "    for line in f:\n",
    "        x_test.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = tokenizer.texts_to_sequences(x_train)\n",
    "test_x = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_lenghts_train = [len(sent) for sent in train_x]\n",
    "sent_lenghts_test = [len(sent) for sent in test_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pad_sequences(train_x,maxlen=MAX_TIME,padding='post')\n",
    "test_x = pad_sequences(test_x,maxlen=MAX_TIME,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordIndex = tokenizer.word_index\n",
    "wI = {}\n",
    "for k,v in wordIndex.items():\n",
    "    if v < VOCAB_SIZE:\n",
    "        wI[k] = v\n",
    "wordIndex = wI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.zeros((len(train_x),MAX_TIME))\n",
    "test_y = np.zeros((len(test_x),MAX_TIME))\n",
    "train_y[:,:-1] = train_x[:,1:]\n",
    "test_y[:,:-1] = test_x[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = VOCAB_SIZE\n",
    "embedding_dim = 300\n",
    "input_data = mx.sym.Variable('data')\n",
    "label = mx.sym.Variable('softmax_label')\n",
    "input_embed = mx.sym.Embedding(data=input_data,input_dim=vocab_size,output_dim=embedding_dim,\\\n",
    "                                   name='embed_weights')\n",
    "lstm_cell = mx.rnn.LSTMCell(num_hidden=LSTM_HIDDEN)\n",
    "begin_state = lstm_cell.begin_state()\n",
    "output, states = lstm_cell.unroll(MAX_TIME,input_embed, begin_state,merge_outputs=True)\n",
    "pred = mx.sym.Reshape(output, shape=(-1, LSTM_HIDDEN))\n",
    "pred = mx.sym.FullyConnected(data=pred, num_hidden=vocab_size, name='pred')\n",
    "pred = mx.sym.Reshape(pred, shape=(-1, vocab_size))\n",
    "\n",
    "label = mx.sym.Reshape(label, shape=(-1,))\n",
    "logits = mx.sym.log_softmax(pred, axis=-1)\n",
    "loss = -mx.sym.pick(logits, label, axis=-1, keepdims=True)\n",
    "loss = mx.sym.mean(loss, axis=0, exclude=True)\n",
    "loss = mx.sym.make_loss(loss, name='nll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "arg_params = {}\n",
    "model = mx.module.Module(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "/home/ayush/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  \n",
      "WARNING:root:optimizer already initialized, ignoring...\n"
     ]
    }
   ],
   "source": [
    "model.bind(data_shapes=[('data',(batch_size,MAX_TIME))], label_shapes=[('softmax_label', (batch_size,MAX_TIME))])\n",
    "model.init_params(initializer=mx.initializer.Uniform(0.1))\n",
    "model.init_optimizer('rmsprop')\n",
    "#optimizer='rmsprop',num_epoch=10,learning_rate=0.005,\\\n",
    "#                                 numpy_batch_size=batch_size,initializer=mx.initializer.Uniform(0.1),\\\n",
    "#                                 arg_params=arg_params\n",
    "bt  =mx.io.DataBatch(data=[tx[0:10]], label=[ty[0:10]])\n",
    "model.forward(bt)\n",
    "model.backward()\n",
    "model.update()\n",
    "outputs = model.get_outputs(merge_multi_context=False)[-1]\n",
    "print(mx.nd.sum(outputs[0]).asscalar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = mx.nd.array(train_x), mx.nd.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3610, 15)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3610"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242.103\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

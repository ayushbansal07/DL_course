{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ayush/anaconda3/lib/python3.6/site-packages/scipy/stats/morestats.py:12: DeprecationWarning: Importing from numpy.testing.decorators is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing.decorators import setastest\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-2-1f4c32b8126e>:1: DeprecationWarning: invalid escape sequence \\s\n",
      "  CLEANING_PATTERN = re.compile(\"[\\s\\n\\r\\t.,:;\\-_\\'\\\"?!#&()\\/%\\[\\]\\{\\}\\<\\>\\\\$@\\!\\*\\+\\=]\")\n"
     ]
    }
   ],
   "source": [
    "CLEANING_PATTERN = re.compile(\"[\\s\\n\\r\\t.,:;\\-_\\'\\\"?!#&()\\/%\\[\\]\\{\\}\\<\\>\\\\$@\\!\\*\\+\\=]\")\n",
    "VOCAB_SIZE = 5800\n",
    "MAX_TIME = 15\n",
    "LSTM_HIDDEN = 256\n",
    "MAX_NORM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "with open('train.txt') as f:\n",
    "    for line in f:\n",
    "        x_train.append(line)\n",
    "\n",
    "with open('test.txt') as f:\n",
    "    for line in f:\n",
    "        x_test.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = tokenizer.texts_to_sequences(x_train)\n",
    "test_x = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_lenghts_train = [len(sent) for sent in train_x]\n",
    "sent_lenghts_test = [len(sent) for sent in test_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pad_sequences(train_x,maxlen=MAX_TIME,padding='post')\n",
    "test_x = pad_sequences(test_x,maxlen=MAX_TIME,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = np.zeros((len(train_x),MAX_TIME))\n",
    "test_y = np.zeros((len(test_x),MAX_TIME))\n",
    "train_y[:,:-1] = train_x[:,1:]\n",
    "test_y[:,:-1] = test_x[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = mx.nd.array(train_x)\n",
    "train_y = mx.nd.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordIndex = tokenizer.word_index\n",
    "wI = {}\n",
    "for k,v in wordIndex.items():\n",
    "    if v < VOCAB_SIZE:\n",
    "        wI[k] = v\n",
    "wordIndex = wI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = mx.contrib.text.vocab.Vocabulary(Counter(tokenizer.word_counts))\n",
    "my_indexing = [0]\n",
    "for i in range(1,VOCAB_SIZE):\n",
    "    myword = tokenizer.index_word[i]\n",
    "    my_indexing.append(vocabulary.token_to_idx[myword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_FILE = 'glove.6B.200d.txt'\n",
    "embeddings = mx.contrib.text.embedding.GloVe(EMBEDDINGS_FILE,embedding_root='./',vocabulary=vocabulary)\n",
    "all_tokens = vocabulary.to_tokens(list(range(len(vocabulary))))\n",
    "weight_matrix = embeddings.get_vecs_by_tokens(all_tokens)\n",
    "weight_matrix = weight_matrix[my_indexing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _clip_by_global_norm(_module,max_norm):\n",
    "        assert _module.binded and _module.params_initialized \\\n",
    "               and _module.optimizer_initialized\n",
    "        grad_array = []\n",
    "        for grad in _module._exec_group.grad_arrays:\n",
    "            grad_array += grad\n",
    "        return mx.gluon.utils.clip_global_norm(grad_array, max_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = VOCAB_SIZE\n",
    "embedding_dim = 200\n",
    "input_data = mx.sym.Variable('data')\n",
    "label = mx.sym.Variable('softmax_label')\n",
    "input_embed = mx.sym.Embedding(data=input_data,input_dim=vocab_size,output_dim=embedding_dim,\\\n",
    "                                   name='embed')\n",
    "lstm_cell = mx.rnn.LSTMCell(num_hidden=LSTM_HIDDEN)\n",
    "begin_state = lstm_cell.begin_state()\n",
    "output, states = lstm_cell.unroll(MAX_TIME,input_embed, begin_state,merge_outputs=True)\n",
    "pred = mx.sym.Reshape(output, shape=(-1, LSTM_HIDDEN))\n",
    "pred = mx.sym.FullyConnected(data=pred, num_hidden=vocab_size, name='pred')\n",
    "pred = mx.sym.Reshape(pred, shape=(-1, vocab_size))\n",
    "\n",
    "label = mx.sym.Reshape(label, shape=(-1,))\n",
    "loss = mx.sym.SoftmaxOutput(data=pred,label=label)\n",
    "#logits = mx.sym.log_softmax(pred, axis=-1)\n",
    "#loss = -mx.sym.pick(logits, label, axis=-1, keepdims=True)\n",
    "#loss = mx.sym.mean(loss, axis=0, exclude=True)\n",
    "#loss = mx.sym.make_loss(loss, name='nll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "model = mx.module.Module(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bind(data_shapes=[('data',(batch_size,MAX_TIME))], label_shapes=[('softmax_label', (batch_size,MAX_TIME))])\n",
    "model.init_params(initializer=mx.initializer.Uniform(0.1))\n",
    "model.set_params({'embed_weight' : weight_matrix},{},allow_missing=True)\n",
    "model.init_optimizer('rmsprop',optimizer_params=(('learning_rate', 0.005), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Train Loss : 243.957742\n",
      "Epoch 2 : Train Loss : 171.993836\n",
      "Epoch 3 : Train Loss : 167.193367\n",
      "Epoch 4 : Train Loss : 163.276642\n",
      "Epoch 5 : Train Loss : 160.208192\n",
      "Epoch 6 : Train Loss : 157.950610\n",
      "Epoch 7 : Train Loss : 156.119504\n",
      "Epoch 8 : Train Loss : 154.597980\n",
      "Epoch 9 : Train Loss : 153.323816\n",
      "Epoch 10 : Train Loss : 152.226113\n",
      "Epoch 11 : Train Loss : 151.265862\n",
      "Epoch 12 : Train Loss : 150.419106\n",
      "Epoch 13 : Train Loss : 149.665493\n",
      "Epoch 14 : Train Loss : 148.988650\n",
      "Epoch 15 : Train Loss : 148.375703\n",
      "Epoch 16 : Train Loss : 147.816301\n",
      "Epoch 17 : Train Loss : 147.302244\n",
      "Epoch 18 : Train Loss : 146.827192\n",
      "Epoch 19 : Train Loss : 146.386278\n",
      "Epoch 20 : Train Loss : 145.975675\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "num_batches = int(len(train_x)/batch_size)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = 0\n",
    "    eval_metric = mx.metric.CrossEntropy()\n",
    "    for i in range(num_batches):\n",
    "        bt = mx.io.DataBatch(data=[train_x[i*batch_size:(i+1)*batch_size]], label=[train_y[i*batch_size:(i+1)*batch_size]])\n",
    "        model.forward(bt)\n",
    "        model.backward()\n",
    "        _clip_by_global_norm(model,MAX_NORM*batch_size*MAX_TIME)\n",
    "        model.update()\n",
    "        outputs = model.get_outputs(merge_multi_context=True)\n",
    "        eval_metric.update(train_y[i*batch_size:(i+1)*batch_size].reshape(-1,),outputs[0])\n",
    "        train_loss += eval_metric.get()[1]\n",
    "    print(\"Epoch %d : Train Loss : %f\"%(epoch+1,train_loss))\n",
    "    model.save_checkpoint(\"model\",10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for last word\n",
    "\n",
    "test_accuracy_1 = 0\n",
    "num_batches = int(len(test_x)/batch_size)\n",
    "for i in range(num_batches):\n",
    "    bt = mx.io.DataBatch(data=[train_x[i*batch_size:(i+1)*batch_size]], label=[train_y[i*batch_size:(i+1)*batch_size]])\n",
    "    model.forward(bt)\n",
    "    test_outs = model.get_outputs(merge_multi_context=True)[0].asnumpy()\n",
    "    test_outs = test_outs.reshape((batch_size,MAX_TIME,-1))\n",
    "    test_preds = np.argmax(test_outs,axis=-1)\n",
    "    batch_y = np.array(test_y[i*batch_size:(i+1)*batch_size],dtype='int64')\n",
    "    idxing = range(batch_size),np.array(sent_lenghts_test[i*batch_size:(i+1)*batch_size])-1\n",
    "    acc = np.sum(test_preds[idxing] == batch_y[idxing])\n",
    "    test_accuracy_1 += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Task 1 :  0.845\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy for Task 1 : \",test_accuracy_1/(num_batches*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for 2nd half of sentence\n",
    "\n",
    "test_accuracy_2 = 0\n",
    "num_preds = 0\n",
    "num_batches = int(len(test_x)/batch_size)\n",
    "for i in range(num_batches):\n",
    "    bt = mx.io.DataBatch(data=[train_x[i*batch_size:(i+1)*batch_size]], label=[train_y[i*batch_size:(i+1)*batch_size]])\n",
    "    model.forward(bt)\n",
    "    test_outs = model.get_outputs(merge_multi_context=True)[0].asnumpy()\n",
    "    test_outs = test_outs.reshape((batch_size,MAX_TIME,-1))\n",
    "    test_preds = np.argmax(test_outs,axis=-1)\n",
    "    batch_y = np.array(test_y[i*batch_size:(i+1)*batch_size],dtype='int64')\n",
    "    ct = 0\n",
    "    \n",
    "    for j in range(i*batch_size,(i+1)*batch_size):\n",
    "        baselen = sent_lenghts_test[j]\n",
    "        encodelen = int(baselen/2)\n",
    "        sent_preds = test_preds[ct,range(encodelen-1,baselen)]\n",
    "        sent_batch = batch_y[ct,range(encodelen-1,baselen)]\n",
    "        test_accuracy_2 += np.sum(sent_batch == sent_preds)\n",
    "        num_preds += len(sent_preds)\n",
    "        ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Task 2 :  0.18640712636093698\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy for Task 2 : \",test_accuracy_2/num_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
